{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I exported the data set in gz: in this format, it takes less space\n",
    "# I did it in the following way:\n",
    "# df = pd.read_csv(\"data/20201112_ccpp_drs_processed.csv\", decimal=',', sep=';')\n",
    "# df.evidencelevelreeval = df.evidencelevelreeval.fillna('-').astype(np.str)\n",
    "# df.to_csv(\"data/my_20201112.gz\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 349)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For an example, i take just 10 first rows\n",
    "df = pd.read_csv(\"../data/my_20201112.gz\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move some variables\n",
    "(it is more convenient this way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_end(df, col_name):\n",
    "    col = df[col_name]\n",
    "    df.pop(col_name)\n",
    "    idx = df.shape[1]\n",
    "    df.insert(idx, col_name, col)\n",
    "\n",
    "def move_to_begining(df, col_name):\n",
    "    col = df[col_name]\n",
    "    df.pop(col_name)\n",
    "    df.insert(0, col_name, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_to_end(df, \"rnafold_37_dot_par\")\n",
    "move_to_end(df, \"rnafold_75_dot_par\")\n",
    "move_to_end(df, \"blastscore\")\n",
    "move_to_end(df, 'cas_prox_class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct cas_prox_subtype and cas_prox_type  target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'cas_prox_class':'cas_prox_subtype'})\n",
    "cas_prox_subtype = list(map(lambda s: s.replace('IV', 'IIII'), df.cas_prox_subtype))\n",
    "cas_prox_subtype = list(map(lambda s: s.replace('V', 'IIIII'), cas_prox_subtype))\n",
    "cas_prox_subtype = list(map(lambda s: s.replace('VI', 'IIIIII'), cas_prox_subtype))\n",
    "df['cas_prox_type'] = list(map(lambda s: s.count('I'), cas_prox_subtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct crispr/not-crispr target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasya/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/vasya/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/vasya/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/vasya/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "df = df.astype({\"blastscore\": float})\n",
    "df = df.assign(crispr=np.repeat(-1, df.shape[0]))\n",
    "## all el4 are good\n",
    "df.crispr[df.evidencelevel == 4] = 1\n",
    "## all el1 are notgood\n",
    "df.crispr[df.evidencelevel == 1] = 0\n",
    "## all el1 that have blast score higher than 40 are reassigned to el4\n",
    "df.crispr[np.logical_and(df.evidencelevel == 1, df.blastscore > 40)] = 1\n",
    "## we exclude from the 0 dataset all DR than have blast < 40 but >10\n",
    "df.crispr[np.logical_and.reduce((df.evidencelevel==1, df.blastscore<40, df.blastscore>10))] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removal of repetitive ids and canonical k-mers construction\n",
    "1. In the data set, for each DR a reverse complement (RC) was generated.\n",
    "2. To construct canonical k-mers, a DR and its RC is used (AAA_new = AAA_dr + AAA_rc). Then, the sample size will be n/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repetitive_id(df):\n",
    "    \"\"\"\n",
    "    Keep those with a minimal rnafold 37 energy\n",
    "    \"\"\"\n",
    "    unique_ids = np.unique(df.id)\n",
    "    unique_rows = many_unique_ids(unique_ids)\n",
    "    return pd.concat(unique_rows, axis=1).T\n",
    "\n",
    "def _for_one_unique_id(id_):\n",
    "    repetitive_instances = df.loc[df.id == id_]\n",
    "    repetitive_ids = repetitive_instances.index\n",
    "    min_energy_id = repetitive_ids[df.rnafold_37_energy[repetitive_ids].argmin()]\n",
    "    final_example = df.loc[min_energy_id, :]\n",
    "    final_example.iloc[11:331] = repetitive_instances.iloc[:, 11:331].sum(axis=0)\n",
    "    return final_example\n",
    "\n",
    "many_unique_ids = np.vectorize(_for_one_unique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasya/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df2 = remove_repetitive_id(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove reverse complement mers\n",
    "Since canonical mers are used, there is no need in RC mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_complement(seq):\n",
    "    rc = seq[::-1]\n",
    "    rc = rc.replace('A', '*')\n",
    "    rc = rc.replace('T', 'A')\n",
    "    rc = rc.replace('*', 'T')\n",
    "    rc = rc.replace('C', '*')\n",
    "    rc = rc.replace('G', 'C')\n",
    "    rc = rc.replace('*', 'G')\n",
    "    return rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sufficient_mers(mers):\n",
    "    res = []\n",
    "    for mer in mers:\n",
    "        rc = reverse_complement(mer)\n",
    "        if rc == mer:\n",
    "            res.append(mer)\n",
    "        else:\n",
    "            if rc not in res:\n",
    "                res.append(mer)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 199)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_keep = find_sufficient_mers(df.columns[11:75]) + find_sufficient_mers(df.columns[75:331])\n",
    "to_delete = pd.Index(np.setdiff1d(df.columns[11:331], to_keep))\n",
    "df2 = df2.drop(to_delete, axis='columns')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AAA', 'AAT', 'AAG', 'AAC', 'ATA', 'ATG', 'ATC', 'AGA', 'AGT', 'AGG',\n",
       "       'AGC', 'ACA', 'ACG', 'ACC', 'TAA', 'TAG', 'TAC', 'TTG', 'TTC', 'TGA',\n",
       "       'TGG', 'TGC', 'TCG', 'TCC', 'GAG', 'GAC', 'GTG', 'GGG', 'GGC', 'GCG',\n",
       "       'CAG', 'CGG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 mers\n",
    "df2.columns[11:43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AAAA', 'AAAT', 'AAAG', 'AAAC', 'AATA', 'AATT', 'AATG', 'AATC', 'AAGA',\n",
       "       'AAGT',\n",
       "       ...\n",
       "       'CAAG', 'CATG', 'CAGG', 'CACG', 'CTAG', 'CTGG', 'CTCG', 'CGGG', 'CGCG',\n",
       "       'CCGG'],\n",
       "      dtype='object', length=136)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 mers\n",
    "df2.columns[43:179]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rnafold_37_energy', 'rnafold_37_frequence', 'rnafold_37_diversity',\n",
       "       'rnafold_37_stem', 'rnafold_37_stem_diff', 'rnafold_37_loop',\n",
       "       'rnafold_37_stem_loop_nbr', 'rnafold_75_energy', 'rnafold_75_frequence',\n",
       "       'rnafold_75_diversity', 'rnafold_75_stem', 'rnafold_75_stem_diff',\n",
       "       'rnafold_75_loop', 'rnafold_75_stem_loop_nbr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rnafold\n",
    "df2.columns[179:193]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourmers = joblib.load('models/crispr/4mers-model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fourmers.predict(df2.iloc[:, 43:179])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of unknown and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-8531bd22c214>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# okay, here, it doesn't work because i took 10 examples without their rc counterparts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrispr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of unknown and binary targets"
     ]
    }
   ],
   "source": [
    "# okay, here, it doesn't work because i took 10 examples without their rc counterparts\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(df2.crispr, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
